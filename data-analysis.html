
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  
<!-- Mirrored from www.statisticsdonewrong.com/data-analysis.html by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 26 Feb 2026 14:54:50 GMT -->
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>An introduction to data analysis &#8212; Statistics Done Wrong</title>
    <link rel="stylesheet" href="_static/book.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0th',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,400italic" rel="stylesheet" type="text/css">
    <link rel="canonical" href="data-analysis.html" />
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Statistical power and underpowered statistics" href="power.html" />
    <link rel="prev" title="Introduction" href="introduction.html" />
 
  </head>
  <body>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="an-introduction-to-data-analysis">
<h1>An introduction to data analysis<a class="headerlink" href="#an-introduction-to-data-analysis" title="Permalink to this headline">¶</a></h1>
<p>Much of experimental science comes down to measuring changes. Does one medicine
work better than another? Do cells with one version of a gene synthesize more of
an enzyme than cells with another version? Does one kind of signal processing
algorithm detect pulsars better than another? Is one catalyst more effective at
speeding a chemical reaction than another?</p>
<p>Much of statistics, then, comes down to making judgments about these kinds of
differences. We talk about “statistically significant differences” because
statisticians have devised ways of telling if the difference between two
measurements is really big enough to ascribe to anything but chance.</p>
<p>Suppose you’re testing cold medicines. Your new medicine promises to cut the
duration of cold symptoms by a day. To prove this, you find twenty patients with
colds and give half of them your new medicine and half a placebo. Then you track
the length of their colds and find out what the average cold length was with and
without the medicine.</p>
<p>But all colds aren’t identical. Perhaps the average cold lasts a week, but some
last only a few days, and others drag on for two weeks or more, straining the
household Kleenex supply. It’s possible that the group of ten patients receiving
genuine medicine will be the unlucky types to get two-week colds, and so you’ll
falsely conclude that the medicine makes things worse. How can you tell if
you’ve proven your medicine works, rather than just proving that some patients
are unlucky?</p>
<div class="section" id="the-power-of-p-values">
<span id="p-values"></span><span id="index-0"></span><h2>The power of <em>p</em> values<a class="headerlink" href="#the-power-of-p-values" title="Permalink to this headline">¶</a></h2>
<p>Statistics provides the answer. If we know the <em>distribution</em> of typical cold
cases – roughly how many patients tend to have short colds, or long colds, or
average colds – we can tell how likely it is for a random sample of cold
patients to have cold lengths all shorter than average, or longer than average,
or exactly average. By performing a statistical test, we can answer the question
“If my medication were completely ineffective, what are the chances I’d see data
like what I saw?”</p>
<p>That’s a bit tricky, so read it again.</p>
<p>Intuitively, we can see how this might work. If I only test the medication on
one person, it’s unsurprising if he has a shorter cold than average –
about half of patients have colds shorter than average. If I test the medication
on ten million patients, it’s pretty damn unlikely that <em>all</em> of them will have
shorter colds than average, <em>unless my medication works.</em></p>
<p>The common statistical tests used by scientists produce a number called
the <em>p</em> value that quantifies this. Here’s how it’s defined:</p>
<blockquote>
<div>The P value is defined as the probability, under the assumption of no effect
or no difference (the null hypothesis), of obtaining a result equal to or more
extreme than what was actually observed.<span class="citation"><sup><a class="reference internal" href="zbibliography.html#citation-goodman-1999tx">24</a></sup></span></div></blockquote>
<p>So if I give my medication to 100 patients and find that their colds are a day
shorter on average, the <em>p</em> value of this result is the chance that, if my
medication didn’t do anything at all, my 100 patients would randomly have, on
average, day-or-more-shorter colds. Obviously, the <em>p</em> value depends on the size
of the effect – colds shorter by four days are less likely than colds shorter
by one day – and the number of patients I test the medication on.</p>
<p>That’s a tricky concept to wrap your head around. A <em>p</em> value is not a measure
of how right you are, or how significant the difference is; it’s a measure
of <em>how surprised you should be</em> if there is no actual difference between the
groups, but you got data suggesting there is. A bigger difference, or one backed
up by more data, suggests more surprise and a smaller <em>p</em> value.</p>
<p>It’s not easy to translate that into an answer to the question “is there really
a difference?”  Most scientists use a simple rule of thumb: if <em>p</em> is less than
0.05, there’s only a 5% chance of obtaining this data unless the medication
really works, so we will call the difference between medication and placebo
“significant.”  If <em>p</em> is larger, we’ll call the difference insignificant.</p>
<p>But there are limitations. The <em>p</em> value is a measure of surprise, not a measure
of the size of the effect. I can get a tiny <em>p</em> value by either measuring a huge
effect – “this medicine makes people live four times longer” – or by measuring
a tiny effect with great certainty. Statistical significance does not mean your
result has any <em>practical</em> significance.</p>
<p>Similarly, statistical <em>in</em>significance is hard to interpret. I could have a
perfectly good medicine, but if I test it on ten people, I’d be hard-pressed to
tell the difference between a real improvement in the patients and plain good
luck. Alternately, I might test it on thousands of people, but the medication
only shortens colds by three minutes, and so I’m simply incapable of detecting
the difference. A statistically insignificant difference does not mean there is
no difference at all.</p>
<p>There’s no mathematical tool to tell you if your hypothesis is true; you can
only see whether it is consistent with the data, and if the data is sparse or
unclear, your conclusions are uncertain.</p>
<p>But we can’t let that stop us.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo"><a href="index-2.html">
  <img class="logo" width="220" height="330" 
       src="_static/cover.png" alt="Logo"/>
</a></p>
<div id="book_ad">
  <h3>There's a book!</h3>
    <p class="topless">
      The revised and expanded <cite>Statistics Done Wrong</cite>, with three times as
      many statistical errors and examples, is
      <a href="http://www.nostarch.com/statsdonewrong">available in print and
        eBook!</a> An essential book for any scientist, data scientist, or statistician.
    </p>
    <p><a class="button" href="http://www.nostarch.com/statsdonewrong">Buy it!</a></p>
    <p>(or use <a href="http://www.amazon.com/Statistics-Done-Wrong-Woefully-Complete/dp/1593276206/">Amazon</a>,
      <a href="http://www.indiebound.org/book/9781593276201">IndieBound</a>, <a href="http://www.bookdepository.com/Statistics-Done-Wrong-Alex-Reinhart/9781593276201">Book Depository</a>,
      or <a href="http://www.barnesandnoble.com/w/statistics-done-wrong-alex-reinhart/1120359162?ean=9781593276201">BN</a>.)</p>
    <p>(or <a href="https://mitp.de/IT-WEB/Statistik/Statistics-Done-Wrong-Deutsche-Ausgabe.html">Deutsch</a>,
    <a href="http://www.aladin.co.kr/shop/wproduct.aspx?ItemId=64707803">한국어</a>,
    <a href="https://www.amazon.it/dp/885180284X/">Italiano</a>,
    <a href="https://www.amazon.cn/dp/B01LY7GFOD/">中文 (简体)</a>,
    <a href="http://www.cite.com.tw/book?id=75600">中文 (繁體)</a>,
    <a href="http://www.keisoshobo.co.jp/book/b272873.html">日本語</a>.)
    </p>
</div>

<h3><a href="index-2.html">Table Of Contents</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">An introduction to data analysis</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#the-power-of-p-values">The power of <em>p</em> values</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="power.html">Statistical power and underpowered statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="pseudoreplication.html">Pseudoreplication: choose your data wisely</a></li>
<li class="toctree-l1"><a class="reference internal" href="p-value.html">The <em>p</em> value and the base rate fallacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="significant-differences.html">When differences in significance aren’t significant differences</a></li>
<li class="toctree-l1"><a class="reference internal" href="regression.html">Stopping rules and regression to the mean</a></li>
<li class="toctree-l1"><a class="reference internal" href="freedom.html">Researcher freedom: good vibrations?</a></li>
<li class="toctree-l1"><a class="reference internal" href="mistakes.html">Everybody makes mistakes</a></li>
<li class="toctree-l1"><a class="reference internal" href="hiding.html">Hiding the data</a></li>
<li class="toctree-l1"><a class="reference internal" href="results.html">What have we wrought?</a></li>
<li class="toctree-l1"><a class="reference internal" href="what-next.html">What can be done?</a></li>
<li class="toctree-l1"><a class="reference internal" href="conclusion.html">Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="zbibliography.html">Bibliography</a></li>
</ul>

<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="https://www.statisticsdonewrong.com/search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
<div class="related">
  <h3>Navigation</h3>
  <ul>
    
    <li><a href="introduction.html">Previous</a></li>
    
    
    <li class="right">Next chapter: <a href="power.html">Statistical power and underpowered statistics</a></li>

  </ul>
</div>

  <div class="footer">
    <a rel="license"
    href="https://creativecommons.org/licenses/by/4.0/"><img
    alt="Creative Commons License" style="border-width:0"
    src="../licensebuttons.net/l/by/4.0/88x31.png" /></a><br /><span
    style="font-style:italic" xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Statistics Done Wrong</span> by <a xmlns:cc="http://creativecommons.org/ns#"
    property="cc:attributionName" href="https://www.refsmmat.com/">Alex Reinhart</a> is licensed under a <a
    rel="license"
    href="https://creativecommons.org/licenses/by/4.0/">Creative
    Commons Attribution 4.0 International License</a>.
  </div>
  
    <div class="footer" role="contentinfo">
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.7.
    </div>

  </body>

<!-- Mirrored from www.statisticsdonewrong.com/data-analysis.html by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 26 Feb 2026 14:54:50 GMT -->
</html>